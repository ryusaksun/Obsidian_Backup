根据您提供的课件 `mac02.pdf` 以及复习大纲，非精确一维搜索旨在以较低的计算代价找到一个"可接受"的步长 $\alpha_k$，而不是像精确搜索那样寻找极小值点。

资料中重点介绍了两大准则：Wolfe 准则和 Armijo 准则。

### 1. Wolfe 准则

Wolfe 准则被认为是非精确一维搜索中比较完善的准则，它同时保证了步长既不会太大，也不会太小。它包含两个条件：

- 条件一：充分下降条件要求函数值的下降量必须与其切线方向的下降量成一定比例。公式为： $$ f(x_k + \alpha_k d_k) \le f(x_k) + \rho \alpha_k g_k^T d_k $$ 其中 $\rho \in (0, 0.5)$ 是常数（通常取很小的值，如 $10^{-4}$）。这实际上就是 Armijo 条件，它保证了步长 $\alpha_k$ 不会太大，从而使得函数值有足够的下降。
- 条件二：曲率条件为了防止步长 $\alpha_k$ 选得过小，要求在新的点的斜率（梯度与方向的内积）比初始斜率更大（即更接近于 0 或为正）。公式为： $$ \nabla f(x_k + \alpha_k d_k)^T d_k \ge \sigma g_k^T d_k $$ 其中 $\sigma \in (\rho, 1)$ 是常数。这个条件排除了那些步长过小、远离极小值点的 $\alpha_k$。
- 强 Wolfe 准则：在实际应用中，常使用更严格的强 Wolfe 准则，将条件二加强为： $$ |\nabla f(x_k + \alpha_k d_k)^T d_k| \le -\sigma g_k^T d_k $$ 这限制了新点的梯度绝对值不能太大，保证新点接近极小值点（极小值点梯度为 0）。

### 2. Armijo 准则

Armijo 准则是一种操作更简单、在实际算法（如回溯法）中应用最广泛的准则。

- 核心思想：它只显式地要求满足充分下降条件（即 Wolfe 准则的第一个条件），但通过回溯法的操作方式来间接避免步长过小的问题。
- 具体算法步骤：

    1. 设定参数 $\beta \in (0, 1)$ （衰减因子，例如 0.5），$\sigma \in (0, 0.5)$ （下降参数）。
    2. 令初始步长 $\alpha = 1$（或其他初始值）。
    3. 判断：检查当前的 $\alpha$ 是否满足如下不等式： $$ f(x_k + \alpha d_k) \le f(x_k) + \sigma \alpha g_k^T d_k $$
    4. 更新：
        - 如果满足，则接受该 $\alpha$ 作为 $\alpha_k$。
        - 如果不满足，则令 $\alpha := \beta \alpha$（例如缩小一半），重复步骤 3，直到满足为止。

### 总结

- Wolfe 准则：理论上更严谨，包含下降和曲率两个显式条件，常用于理论证明和高精度的拟牛顿法中。
- Armijo 准则：是 Wolfe 准则的简化版（只保留了下降条件），配合回溯法使用，计算简单，在实际工程（如最速下降法、牛顿法）中非常常用。复习大纲中提到的"采用非精确算法（2种选择一种）"，通常指的就是在 Armijo 和 Wolfe 之间选择，或者直接手写 Armijo 的回溯过程。

---

**<font color="#2ecc71">✅ 已格式化</font>**
