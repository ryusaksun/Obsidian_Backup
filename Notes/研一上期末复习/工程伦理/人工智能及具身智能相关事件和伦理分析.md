## 1. 绪论：从信息处理到物理存在的范式跨越

### 1.1 具身智能的本体论定义与演进

在人工智能（AI）长达数十年的发展历程中，技术界长期致力于构建能够处理符号、逻辑和生成内容的离身智能（Disembodied AI）。这类智能体存在于服务器和云端，以 ChatGPT 为代表的大语言模型（LLM）是其巅峰形态，它们在处理文本、代码和图像等数字信息方面表现出了超越人类的能力。然而，正如机器人学家汉斯·莫拉维克（Hans Moravec）在 20 世纪 80 年代所提出的莫拉维克悖论指出：让计算机在智力测试或下棋中击败人类相对容易，但要赋予它们如一岁儿童般的感知和行动能力却极其困难。

进入 2024 年至 2025 年，随着基础模型能力的溢出与硬件成本的下降，人工智能领域正在经历一场深刻的范式转移——从离身走向具身（Embodied AI）。具身智能不再仅仅是能够通过图灵测试的聊天程序，而是拥有物理实体（Body）、能够感知环境（Perception）、并在非结构化的物理世界中执行任务（Action）的智能系统。

具身智能与传统 AI 的本质区别在于其与物理世界的交互性。传统 AI 是被动的数据处理器，而具身智能是物理世界的主动参与者。根据 NVIDIA 和 Circus Group 的定义，具身智能涵盖了从人形机器人、自动驾驶车辆到智能制造单元等广泛的物理系统。这一转变的核心在于构建感知-认知-行动的闭环（Perception-Action Loop），使得 AI 不仅能读万卷书（处理海量文本数据），还能行万里路（在复杂的物理环境中导航和操作）。

| 特征维度 | 传统人工智能 (Traditional/Informational AI) | 具身智能 (Embodied AI/Physical AI) |
|---|---|---|
| 存在形态 | 虚拟软件、云端算法、API 接口 | 物理实体（机器人、无人车、智能设备） |
| 核心输入 | 结构化数据、文本、像素流 | 多模态传感器数据（视觉、触觉、本体感觉、LiDAR） |
| 核心输出 | 文本生成、图像合成、决策建议 | 物理动作（力矩控制、抓取、移动）、环境改变 |
| 环境特征 | 静态、规则明确、数字原生 | 动态、非结构化、充满不可预测性（摩擦、重力、光照变化） |
| 错误代价 | 信息错误（幻觉）、计算偏差 | 物理伤害、财产损失、安全事故 |
| 典型代表 | ChatGPT, Midjourney, 推荐算法 | Tesla Optimus, Figure 03, Waymo |

### 1.2 2025 年：物理 AI 的寒武纪大爆发

2025 年被广泛认为是具身智能的元年，或者更准确地说，是物理 AI 走出实验室进入商业化前夜的转折点。这一年，技术、资本与政策的三重共振推动了行业的爆发式增长。

- 基础模型的物理化：大语言模型向视觉-语言-动作（Vision-Language-Action, VLA）模型的进化，赋予了机器人理解自然语言指令并将其分解为原子动作序列的能力。例如，DeepMind 的 Gemini Robotics 和 OpenAI 支持的 Figure AI Helix 模型，使得机器人不再需要针对每个动作进行硬编码。

- 仿真到现实（Sim-to-Real）的成熟：利用 NVIDIA Isaac Lab 和 Project GR00T 等平台，开发者可以在物理精确的模拟环境中并行训练数百万个机器人，然后将习得的策略零样本迁移到现实世界。这解决了物理世界数据采集成本高昂且危险的痛点。

- 地缘政治与国家战略的驱动：中美两国均将具身智能视为继半导体之后的下一个战略高地。中国工信部发布的《人形机器人创新发展指导意见》与上海发布的《人形机器人治理导则》明确了 2025-2027 年的发展目标；而美国则通过行政命令和企业联盟加速本土机器人生态的构建。

本报告将深入调查这一领域的关键技术架构、2024-2025 年发生的里程碑事件，并对由此引发的物理安全、隐私泄露、劳工权利及人机伦理问题进行详尽的分析。

---

## 2. 技术架构演进：构建机器人的小脑与大脑

具身智能的实现依赖于底层技术架构的重构。2024-2025 年间，最显著的技术趋势是端到端神经网络在机器人控制中的应用，以及世界模型的引入。

### 2.1 视觉-语言-动作（VLA）模型与双系统架构

传统的机器人控制栈通常是分层的：感知模块识别物体，规划模块生成路径，控制模块计算电机力矩。这种架构虽然稳定，但在面对未见过的场景时缺乏泛化能力。新一代具身智能采用了 VLA 架构，直接将感知输入映射为动作输出。

Figure AI 发布的 Helix 模型展示了目前最先进的架构设计，它采用了类似于人类认知心理学中的双系统理论。

- 系统 1（System 1）：直觉反应层。这是一个基于 Transformer 和扩散模型（Diffusion Model）的视觉运动策略网络，负责高频（200Hz+）、低延迟的动作执行。它直接处理像素级输入，输出关节的连续控制信号。这使得机器人能够处理动态任务，如接住抛来的物体或在打滑时保持平衡。

- 系统 2（System 2）：认知推理层。这是一个大型视觉语言模型（VLM），负责长程任务规划、语义理解和常识推理。当用户发出把桌子上那个红色的、看起来能吃的物体递给我的模糊指令时，系统 2 负责解析意图，分解任务步骤，并将高层指令下发给系统 1 执行。

这种解耦又协作的架构，解决了大模型推理速度慢与机器人控制实时性要求高之间的矛盾。Figure 03 通过这种架构，实现了在双臂协同操作从未见过的物体（Zero-shot generalization）时的极高稳定性。

### 2.2 机器人基础模型（RFM）与世界模型

如果说 VLA 解决了怎么做（How）的问题，那么世界模型（World Model）则赋予了机器人预知后果（What if）的能力。

Covariant 在 2025 年推出的 RFM-1（Robotics Foundation Model 1）标志着这一领域的突破。RFM-1 是一个基于视频生成的生成式世界模型。它不仅学习了物理世界的静态特征，还学习了物理互动的动态规律。

- 物理预测能力：RFM-1 可以生成未来几秒钟的视频预测。例如，在抓取一个堆叠不稳的箱子前，模型可以在脑海中模拟抓取动作，并预测箱子倒塌的视频。这种预测能力允许机器人在执行动作前进行风险评估，从而选择更安全的策略。

- 语言引导的编程：通过理解自然语言，操作员可以用英语告诉机器人稍微向左一点，动作轻一点，而无需重新编写代码。这极大地降低了机器人的部署门槛。

### 2.3 谷歌 DeepMind 的 Gemini Robotics 体系

Google DeepMind 在 2025 年推出了基于 Gemini 2.0 的机器人基础模型体系，包括 Gemini Robotics 和 Gemini Robotics-ER（Embodied Reasoning）。

- 多模态融合：该模型不仅处理视觉和文本，还整合了音频和触觉反馈。在演示中，机器人可以通过听觉判断机器运转是否正常，或通过触觉反馈调整抓取力度。

- 长程推理：Gemini Robotics-ER 专注于解决长视界（Long-horizon）任务，即那些需要数十个步骤才能完成的复杂任务（如做一顿早餐）。它能够记住之前的步骤状态，并根据环境变化动态调整后续计划。

### 2.4 仿真技术的跃迁：NVIDIA GR00T 与 Isaac Lab

数据是 AI 的燃料，但物理世界的数据采集既昂贵又危险。NVIDIA 在 2025 年通过 Project GR00T 和 Isaac Lab 彻底改变了这一局面。

- 合成数据飞轮：利用 NVIDIA Cosmos 世界模型生成多样化的虚拟场景，并在 Isaac Lab 中进行基于物理引擎（Newton Physics Engine）的高保真模拟。机器人在虚拟世界中经历数百万次失败和尝试，学习跑步、跳跃和精细操作，然后将训练好的策略部署到实体机器人上。

- 硬件加速：Blackwell 架构的 GPU 为这种大规模并行仿真提供了算力支持，使得数千个机器人可以在数分钟内完成现实世界需要数年才能完成的训练量。

---

## 3. 2024-2025 年具身智能关键事件调查

过去两年是具身智能从实验室走向生产线的关键时期，全球范围内发生了多起标志性事件，既有令人振奋的商业落地，也有引发深思的技术故障。

### 3.1 商业化里程碑：从工厂到物流

#### 3.1.1 Figure AI 与 BMW 的斯帕坦堡实战

2025 年，Figure AI 与 BMW 的合作成为了具身智能工业落地的标杆案例。Figure 02 机器人在 BMW 位于南卡罗来纳州斯帕坦堡的工厂进行了长达 11 个月的实地部署测试。

- 任务描述：机器人被整合进底盘车间（Body Shop），负责将钣金零件从料箱中取出，并精确放置到焊接夹具上。这是一个典型的拾取-放置（Pick-and-Place）任务，但要求极高的精度（毫米级）和重复性。

- 关键数据：在测试期间，机器人参与了超过 30,000 辆 BMW X3 的生产，搬运了超过 90,000 个零件，累计运行时间超过 1,250 小时，行走里程超过 200 英里。最关键的是，其操作准确率达到了 99% 以上，且平均周期时间（Cycle Time）通过优化达到了工业节拍要求。

- 意义：这证明了通用人形机器人可以在不改变现有生产线布局的情况下，直接替代人类工人的工位，这是专用自动化设备无法做到的。

#### 3.1.2 Agility Robotics Digit 的合规突破

Agility Robotics 的 Digit 机器人（采用反关节双足设计）在 2025 年获得了 OSHA（美国职业安全与健康管理局）认可的国家测试实验室（NRTL）的安全认证。这是首个获得此类认证的商用人形机器人，意味着它符合了并在人类工作环境中运行的严格安全标准。

- 应用扩展：获得认证后，Digit 被允许进入亚马逊和 GXO Logistics 的履约中心，执行周转箱搬运（Tote Recycling）任务。Digit 展示了其在适应人类设计的楼梯、狭窄通道方面的优势。

### 3.2 竞争格局与百团大战

#### 3.2.1 特斯拉 Optimus 的迭代与挫折

特斯拉的 Optimus 项目一直是行业的流量中心。

- Gen 2 进化：2024-2025 年间，Optimus Gen 2 实现了显著的轻量化（减重 10kg）和灵活性提升（行走速度提升 30%）。其自研的灵巧手具备 11 个自由度，能够处理鸡蛋等易碎品。

- 2025 年演示事故：在 2025 年底的一次高调演示中，Optimus 在尝试复杂的慢跑动作时意外跌倒并无法自主站起。这一事件迅速在社交媒体发酵，被部分评论家称为 2025 年最大的科技失败。

- 分析：尽管遭遇群嘲，但业内专家指出，双足机器人的动态平衡本质上是一个极难的非线性控制问题。这次失败反而暴露了当前 VLA 模型在处理突发物理扰动时的鲁棒性短板，促使行业反思过度营销与技术现实之间的差距。

#### 3.2.2 中国力量的崛起

中国政府将人形机器人列为未来产业的标志性产品，推动了宇树科技（Unitree）、傅利叶智能（Fourier）、小鹏鹏行（XPENG Robotics）等企业的快速发展。

- 宇树 G1：2025 年发布的 Unitree G1 以 9.9 万元人民币的惊人低价震撼市场，展示了中国供应链在成本控制上的极致能力。G1 不仅具备超大的关节运动范围（甚至可以像瑜伽一样折叠），还集成了力控技术。

- 政策支持：上海成立了国家地方共建人形机器人创新中心，发布了开源原型机天工，意在打造机器人的 Linux 时刻。工信部设定了 2025 年实现量产、2027 年达到世界先进水平的战略目标。

#### 3.2.3 失败案例与市场洗牌

并非所有尝试都成功。2025 年，俄罗斯的 AIDOL 机器人在发布会上失控倒塌，被裹在幕布中无法动弹，成为行业笑柄，揭示了部分企业在基础控制算法上的薄弱。同时，一些资金链断裂的初创公司（如 KSL）倒闭，表明具身智能仍是一个极其烧钱且回报周期长的赛道。

---

## 4. 具身智能的伦理分析：多维度的挑战

随着具身智能从数字空间延伸至物理空间，其带来的伦理挑战也从信息偏见升级为物理伤害和社会结构冲击。

### 4.1 物理安全与人机共存风险

具身智能最本质的风险在于其具有造成物理伤害的能力。

- 不可预测性与黑盒风险：基于端到端大模型（VLA）的机器人具有不可解释性。当 Figure 03 通过神经网络决定移动手臂时，没有任何一行代码明确规定了轨迹。在 2025 年的测试中，虽然整体表现优异，但偶发的幻觉动作（如对着空气抓取或突然加速）在工业环境中可能导致严重事故。

- 动态稳定性与挤压风险：双足机器人的跌倒不仅是自身的损坏，更可能砸伤周围的人员。ISO 10218-1:2025 标准更新中，特别强调了功能安全（Functional Safety）和功率及力限制（PFL），要求机器人在检测到碰撞时必须在毫秒级内切断动力。然而，对于重达 70kg 以上的金属机器人，即便是倒塌的惯性也足以造成致命伤害。

- 恶意利用与网络物理攻击：如果黑客入侵了 ChatGPT，后果可能是数据泄露；但如果黑客入侵了家庭机器人，后果可能是机器人被远程控制打开煤气阀门或攻击主人。加州等地已开始立法禁止执法部门使用能够造成物理伤害的杀伤性机器人，但这无法阻止犯罪分子利用改装的商用机器人。

### 4.2 隐私监控的新维度：侧信道与语义地图

具身机器人是终极的移动监控设备，它们在家庭中收集的数据远超智能音箱。

- 全景生活测绘：为了导航，机器人必须构建家庭的 3D 语义地图（Semantic Map）。这不仅包含房间布局，还包含物品摆放（暗示生活习惯）、贵重物品位置等高度敏感信息。Roborock 在 2025 年的隐私政策更新中承认数据可能跨境传输，引发了极大的隐私恐慌。

- 侧信道攻击（Side-channel Attacks）：滑铁卢大学在 2025 年的一项研究揭示了惊人的安全漏洞。研究人员发现，即便机器人与其控制端的通信是加密的，黑客也可以通过监听加密流量的数据包大小和时间间隔（侧信道），以 97% 的准确率推断出机器人正在执行什么动作（如正在打开保险箱或正在去往卧室）。这意味着即使不破解摄像头，机器人的行为模式本身就是泄露隐私的窗口。

### 4.3 劳动替代、工会反击与社会契约

具身智能的经济承诺是解决劳动力短缺，但工人们看到的却是生存威胁。

- 港口自动化罢工：2024-2025 年，美国国际码头工人协会（ILA）发起了针对自动化的激烈罢工。工会明确要求在合同中禁止引入自动化起重机和运输机器人，认为这不仅是就业问题，更是资本剥夺工人议价权的手段。

- 汽车工会的警惕：尽管 BMW 宣称引入 Figure 机器人是为了减少人体工程学负担，全美汽车工人联合会（UAW）对此保持高度警惕。工会指出，一旦机器人的综合成本（TCO）低于人类时薪，大规模替代将不可逆转。工会开始寻求在集体谈判协议中加入技术引入否决权。

- 技能贬值：具身智能不仅替代搬运等简单劳动，正在向焊接、装配等技术工种渗透。这可能导致蓝领中产阶级的技能价值迅速归零，加剧社会贫富差距。

### 4.4 情感计算与弱势群体的伦理困境

在老年护理领域，具身智能被寄予厚望，但也引发了关于非人化的担忧。

- 互惠性的缺失：护理机器人（如 ElliQ 或未来的 Figure 03）可以提供提醒和陪伴，但这种关系是单向的。研究指出，老年人（尤其是痴呆症患者）可能会对机器人产生情感依赖，误以为机器人也关心他们。这种虚假的情感互惠被认为是对人类尊严的冒犯，因为它利用了人类最脆弱的情感需求。

- 客体化风险：将老人的照料完全交给机器，可能被视为一种社会遗弃。伦理学家争辩说，照料（Care）不仅是物理任务的完成，更是人与人之间情感和道德的传递，这是机器永远无法替代的。

---

## 5. 全球治理与法律框架：分裂与弥合

面对具身智能的挑战，全球主要司法管辖区正在构建截然不同的治理框架。

### 5.1 欧盟：基于风险的严格监管与产品责任

欧盟继续扮演全球监管者的角色，通过一系列严苛的法规构建防火墙。

- 《人工智能法案》（EU AI Act）：自 2025 年全面实施以来，具身智能被列为高风险 AI 系统。这意味着所有在欧盟销售的机器人都必须通过严格的第三方合规性评估（Conformity Assessment），包括数据治理、透明度和人类监督机制。

- 《产品责任指令》（Revised Product Liability Directive）：这是 2025 年欧盟立法的一大亮点。新指令明确将软件和 AI 系统纳入产品范畴，并减轻了消费者的举证责任。如果机器人造成伤害（无论是物理伤害还是数据丢失），制造商必须证明自己没有过失，否则将承担严格责任。这解决了算法黑箱导致的问责难题。

### 5.2 中国：产业促进下的伦理规范

中国采取了发展优先，规范并行的策略，特别强调技术标准和伦理导则的制定。

- 《人形机器人治理导则》（上海）：2024 年 7 月发布的这一文件是全球首个专门针对人形机器人的治理框架。

    - 主要内容：包含 30 条具体规则，分为目标愿景、基本遵循、创新发展、风险管理、全球治理等六个部分

    - 核心伦理：明确提出人类优先原则，要求机器人设计必须保障人类安全与尊严；倡导人机共生；并特别强调了风险管理中的急停机制和数据安全

- 标准先行：工信部与北京人形机器人创新中心合作，制定了涵盖运动控制、环境感知和任务执行的国家标准，试图通过标准化来规范行业发展。

### 5.3 美国：市场驱动与诉讼救济

美国的监管相对碎片化，依赖于行政命令和判例法的演进。

- 行政命令 14110：拜登政府的这一命令侧重于 AI 模型的安全性（Safety）和国家安全，要求对前沿模型进行红队测试，但并未针对具身智能制定具体的联邦法规。

- 州级立法：加州 SB 7 法案（No Robo Bosses Act）试图限制 AI 在雇佣决策中的权力，直接影响了企业如何使用机器人来监控和评估工人表现。

- 侵权诉讼（Tort Law）：2025 年的 _Garcia v. Character.AI_ 案成为了风向标。虽然该案涉及的是聊天机器人，但法院倾向于适用产品责任法而非通信法（Section 230）。这预示着未来如果实体机器人造成伤害，美国法院将倾向于让制造商承担巨额赔偿责任，从而倒逼企业提高安全性。

### 5.4 国际标准：ISO 的更新

国际标准化组织（ISO）在 2025 年发布了 ISO 10218-1/2 的重大修订版。

- 变化：新标准不再仅仅关注物理围栏，而是引入了对协作应用的详细规定，要求机器人具备基于传感器的动态限速和力控能力。这为无围栏的人机协作提供了技术合规路径。

| 监管维度 | 欧盟 (EU) | 中国 (China) | 美国 (US) |
|---|---|---|---|
| 治理哲学 | 预防性原则，基本权利至上 | 发展导向，伦理引导，国家安全 | 事后追责，鼓励创新，判例法调节 |
| 关键法规 | EU AI Act, 产品责任指令 | 人形机器人治理导则，数据安全法 | EO 14110, 州级法案 (SB 7) |
| 责任机制 | 严格责任（Strict Liability） | 行政监管与标准合规 | 侵权诉讼（Tort Litigation） |
| 数据主权 | GDPR（极严跨境限制） | 数据出境安全评估 | 针对特定国家的限制（EO 14117） |

---

## 6. 结论与未来展望

### 6.1 调查总结

通过对 2024-2025 年具身智能领域的全面调查，我们得出以下核心结论。

- 技术质变：VLA 模型和仿真技术的结合，已经解决了机器人大脑的通用性问题，使得机器人从专用设备变成了通用智能体。

- 产业落地：汽车制造和物流仓储是具身智能最早的规模化应用场景，而家庭场景虽然前景广阔，但受限于安全性，仍处于早期探索阶段。

- 伦理滞后：现有的伦理和法律框架（尤其是针对物理互动的）明显滞后于技术发展。侧信道攻击、情感操控和劳工替代是当前最紧迫的三大社会风险。

### 6.2 战略建议

- 对于政策制定者：应加速制定针对具身智能的专项安全标准（如强制性的黑匣子数据记录），并在劳工保护方面建立再培训机制，以应对即将到来的就业冲击。

- 对于企业：应摒弃先发布后修复的软件思维。在物理世界中，一个 Bug 可能意味着生命的代价。必须建立从仿真到现实的全链路安全验证体系。

- 对于研究界：需要更多关注可解释性机器人（Explainable Robotics），让人类能够理解机器人动作背后的逻辑，从而建立真正的人机信任。

具身智能正在重塑我们与物理世界的关系。它不仅是工具的延伸，更是人类主体性的映射。在这个物理 AI 的元年，我们不仅需要更强大的算法，更需要更智慧的社会契约。

---

**<font color="#2ecc71">✅ 已格式化</font>**

