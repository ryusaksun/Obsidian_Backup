## 深度解析生成式扩散模型：从去噪扩散概率模型 (DDPM) 到去噪扩散隐式模型 (DDIM) 的数学原理与演进报告

### 第一章 绪论：生成式人工智能的新范式

#### 1.1 生成式模型的演进与挑战

在人工智能的发展历程中，生成式模型（Generative Models）始终占据着核心地位，其目标在于学习真实数据的分布规律，进而生成全新的、具有高度逼真感的数据样本。在扩散模型（Diffusion Models）异军突起之前，该领域长期由生成对抗网络（GANs）、变分自编码器（VAEs）以及基于流的模型（Flow-based Models）所主导。然而，深入分析现有的文献资料 1 可以发现，这些传统模型在实际应用中均面临着被称为生成三难困境（Generative Trilemma）的结构性挑战，即难以同时兼顾样本质量（Quality）、模式覆盖的多样性（Diversity）以及采样速度（Sampling Speed）。

生成对抗网络（GANs）自2014年问世以来，凭借其能够生成极高保真度（High Fidelity）图像的能力而备受推崇。GAN通过生成器与判别器之间的零和博弈进行训练，生成器试图欺骗判别器，而判别器则努力识别真伪。尽管这种对抗机制能够产生清晰锐利的图像，但研究表明 3，GAN的训练过程极不稳定，不仅需要精细调节超参数以维持纳什均衡，还极易陷入模式坍塌（Mode Collapse）的陷阱。模式坍塌意味着模型只能覆盖数据分布中的极小一部分，例如在训练猫的图像生成时，模型可能最终只能生成某一种特定花色的猫，而完全忽略了其他品种。这种多样性的缺失限制了GAN在需要全面探索数据分布场景下的应用。

相比之下，变分自编码器（VAEs）采用概率图模型的框架，通过最大化证据下界（ELBO）来优化模型。VAE的优势在于其坚实的数学基础和训练的稳定性，且不易发生模式坍塌，能够很好地保持生成样本的多样性。然而，VAE生成的图像往往由于损失函数中的重建误差项（通常是均方误差MSE）而显得模糊。这是因为在像素级空间中，最小化MSE倾向于产生所有可能图像的平均值，从而丢失了高频的纹理细节 1。基于流的模型虽然提供了精确的对数似然估计，但其对网络结构的严格可逆性限制（如雅可比行列式的计算要求）极大地束缚了模型的表达能力，且在高维数据上的计算成本极高 2。

在此背景下，扩散模型作为一种全新的生成范式应运而生。去噪扩散概率模型（Denoising Diffusion Probabilistic Models, DDPM）不仅在生成质量上足以媲美甚至超越GAN，同时在模式覆盖的多样性上比肩VAE，并且具有极其稳定的训练过程 1。扩散模型的核心思想受到非平衡热力学的启发，通过模拟数据逐渐被噪声破坏（熵增）的过程，并学习其逆过程（去噪）来从纯噪声中重构数据。尽管DDPM在质量和多样性上取得了突破，但其依赖于数千步迭代的马尔可夫链采样过程导致生成速度极慢，这成为了其实际部署的主要瓶颈。去噪扩散隐式模型（DDIM）随后被提出，通过将采样过程重新表述为非马尔可夫过程，实现了确定性的加速采样，在保持高质量的同时将推理速度提升了数个数量级 7。

#### 1.2 物理直觉：从墨水扩散到逆转时间

为了从底层理解扩散模型，我们首先需要建立物理直觉。早在2015年，Sohl-Dickstein等人就在《Deep Unsupervised Learning using Nonequilibrium Thermodynamics》一文中奠定了扩散模型的物理基础 9。我们可以将扩散过程想象为一滴墨水滴入一杯清水中的过程。

在初始时刻（$t=0$），墨水滴（代表复杂的数据分布，如一张清晰的图像）结构分明，处于低熵状态。随着时间推移（$t$ 增加），墨水分子在水分子的无规则撞击下逐渐扩散。这是一个自发的物理过程，系统的熵不断增加，信息逐渐丢失。最终（$t=T$），墨水分子均匀分布在整杯水中，整杯水变成了均匀的淡蓝色。此时，系统的无序度达到最大，我们可以将其视为高斯噪声（Gaussian Noise）分布。这一过程对应于扩散模型中的前向过程（Forward Process）。

生成式建模的目标则是实现这一物理过程的逆转：如果我们能够像电影倒放一样，精准地逆转时间，引导每一个墨水分子从均匀分布的状态一步步退回到它们最初的位置，我们就能从一杯淡蓝色的水（纯噪声）中还原出那滴墨水（数据）。在计算机视觉的语境下，这意味着模型从一个纯粹的随机高斯噪声向量开始，经过一系列微小的去噪步骤，逐渐雕刻出有意义的图像结构，最终生成一张逼真的图片 11。

与GAN的无中生有（从噪声直接映射到图像）不同，扩散模型更像是一位雕刻家。它不是一次性画出一幅画，而是面对一块粗糙的石头（噪声），通过成千上万次微小的凿击（去噪步骤），逐渐剔除多余的部分，直到显露出内部的雕像。这种迭代式的生成过程虽然计算量大，但却将复杂的生成任务分解为了无数个简单的子任务——在每一步，模型只需要去除一点点噪声即可。这种分解极大地降低了学习的难度，从而保证了训练的稳定性和生成的高质量 13。

#### 1.3 报告结构与目标

本报告旨在为初学者提供一份详尽的、从底层原理出发的扩散模型指南。我们将摒弃浅尝辄止的科普，深入到概率论与线性代数的内核，逐步推导DDPM与DDIM的数学机制。

- 第二章将夯实数学基础，解释为何高斯分布是扩散模型的核心，并详细推导重参数化技巧。

- 第三章将全面解构DDPM，从前向加噪的马尔可夫链性质推导出任意时刻的闭式解，并揭示损失函数是如何从复杂的ELBO简化为直观的噪声预测误差的。

- 第四章将深入探讨DDIM，分析其如何通过引入非马尔可夫假设打破了步长的限制，实现确定性采样与加速，并解释其与DDPM的统一性。

- 第五章将视野扩展至现代应用，特别是Stable Diffusion中的潜在空间扩散技术，以及无分类器引导（Classifier-Free Guidance）等关键技术。

通过本报告，读者将不仅理解怎么做，更能理解为什么，从而在面对日新月异的生成式AI技术时具备透过现象看本质的能力。

---

### 第二章 数学基石：概率分布与变分推断

在深入DDPM和DDIM的具体算法之前，必须构建坚实的数学地基。扩散模型之所以有效，是因为它巧妙地利用了高斯分布的数学特性以及变分推断的近似能力。

#### 2.1 高斯分布的统治地位

在扩散模型的文献中，几乎所有的概率分布——无论是前向过程的加噪，还是反向过程的去噪——都被建模为正态分布（Normal Distribution），即高斯分布。这种选择绝非偶然，而是基于高斯分布在数学运算上的封闭性（Closed-form property）。

##### 2.1.1 两个关键的高斯性质

对于理解扩散模型，以下两个高斯分布的性质至关重要：

1. 高斯分布之和仍为高斯分布：

    如果有两个独立的随机变量 $X \sim \mathcal{N}(\mu_X, \sigma_X^2)$ 和 $Y \sim \mathcal{N}(\mu_Y, \sigma_Y^2)$，那么它们的和 $Z = X + Y$ 依然服从高斯分布，且其参数为：

    $$Z \sim \mathcal{N}(\mu_X + \mu_Y, \sigma_X^2 + \sigma_Y^2)$$

    如果涉及到缩放系数，例如 $Z = aX + bY$，则：

    $$Z \sim \mathcal{N}(a\mu_X + b\mu_Y, a^2\sigma_X^2 + b^2\sigma_Y^2)$$

    这一性质是推导DDPM前向过程闭式解的核心。它意味着，无论我们叠加多少次高斯噪声，最终的结果依然可以通过一个单一的高斯分布来描述 11。

2. 贝叶斯定理下的高斯共轭性：

    如果我们已知先验分布 $P(\theta)$ 是高斯分布，且似然函数 $P(D|\theta)$ 也是高斯分布（且均值是 $\theta$ 的线性函数），那么后验分布 $P(\theta|D)$ 依然是高斯分布。这一性质保证了在反向过程中，如果我们已知 $q(x_t|x_{t-1})$ 和 $q(x_{t-1})$ 是高斯分布，那么反向的条件概率 $q(x_{t-1}|x_t)$ 也可以被近似为高斯分布 14。

在DDPM中，为了简化计算，协方差矩阵通常被限制为对角矩阵 $\Sigma = \sigma^2 \mathbf{I}$。这意味着图像中各个像素点之间的噪声被假设为相互独立的，这大大降低了计算复杂度。

#### 2.2 重参数化技巧 (Reparameterization Trick)

重参数化技巧是深度生成模型（尤其是VAE和扩散模型）中最为关键的工程技巧之一。它解决了如何对包含随机采样的计算图进行反向传播的问题 12。

假设我们想要从高斯分布 $\mathcal{N}(\mu, \sigma^2)$ 中采样一个变量 $z$。直接的采样操作（Sampling operation）在计算图中是一个断点，因为梯度无法穿过随机性进行传播。为了让梯度能够流过均值 $\mu$ 和方差 $\sigma^2$（这些通常是神经网络的输出），我们将 $z$ 重写为：

$$z = \mu + \sigma \cdot \epsilon, \quad \text{其中} \quad \epsilon \sim \mathcal{N}(0, \mathbf{I})$$

在这个公式中：

- $\epsilon$ 是从标准正态分布中采样的随机噪声，它包含了所有的随机性，且不依赖于模型参数。

- $\mu$ 和 $\sigma$ 是确定性的参数。

- 整个操作变成了简单的加法和乘法运算，这对于神经网络框架（如PyTorch或TensorFlow）来说是完全可导的。

在DDPM的前向过程中，这个技巧被反复使用。每一次加噪操作 $x_t \leftarrow x_{t-1}$ 实际上就是一次重参数化采样。通过连续应用这个技巧，我们可以将 $x_t$ 直接表示为 $x_0$ 和一个综合噪声项的函数，而不需要一步步进行采样 13。

#### 2.3 变分下界 (ELBO) 与 KL 散度

生成模型的核心目标是最大化观测数据 $x$ 的对数似然 $\log p_\theta(x)$。然而，对于像扩散模型这样包含隐变量（Latent Variables，即中间的噪声图 $x_1, \dots, x_T$）的模型，直接计算边际似然 $\int p_\theta(x, x_{1:T}) dx_{1:T}$ 是不可行的（Intractable）。

因此，我们退而求其次，最大化对数似然的一个下界，即证据下界（Evidence Lower Bound, ELBO）。根据Jensen不等式，ELBO定义为：

$$\log p_\theta(x) \geq \mathbb{E}_{q} - D_{KL}(q(x_{1:T}|x) | p_\theta(x_{1:T}))$$

在扩散模型的语境下，这个复杂的公式最终被分解为一系列KL散度（Kullback-Leibler Divergence）项。KL散度用于衡量两个概率分布之间的差异。DDPM的训练过程，本质上就是最小化真实的前向后验分布 $q(x_{t-1}|x_t, x_0)$ 与模型预测的反向分布 $p_\theta(x_{t-1}|x_t)$ 之间的KL散度。

值得庆幸的是，由于涉及的分布都是高斯分布，两个高斯分布之间的KL散度拥有解析解（Analytical Solution），即可以通过均值和方差的简单的代数运算直接计算，而不需要进行蒙特卡洛采样近似。这为DDPM能够推导出简洁的均方误差（MSE）损失函数奠定了数学基础 16。

---

### 第三章 DDPM详解：去噪扩散概率模型

2020年，Jonathan Ho等人发表的论文《Denoising Diffusion Probabilistic Models》不仅在理论上统一了扩散模型与变分推断，更在工程上证明了扩散模型可以生成高质量的图像 15。DDPM由两个互逆的过程组成：固定的前向扩散过程和可学习的反向去噪过程。

#### 3.1 前向过程：信息的系统性毁灭

前向过程（Forward Process），也被称为扩散过程（Diffusion Process），是一个参数固定的马尔可夫链（Markov Chain）。它的作用是逐步向数据中添加高斯噪声，直到数据被完全破坏。

##### 3.1.1 马尔可夫链定义

给定真实数据分布 $x_0 \sim q(x_0)$，我们定义一个方差调度表（Variance Schedule）$\{\beta_t \in (0, 1)\}_{t=1}^T$。在每一个时间步 $t$，我们根据前一个时刻的图像 $x_{t-1}$ 生成当前时刻的图像 $x_t$：

$$q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1 - \beta_t} x_{t-1}, \beta_t \mathbf{I})$$

这里的参数设计非常关键：

- 均值 $\sqrt{1 - \beta_t} x_{t-1}$：系数 $\sqrt{1 - \beta_t}$ 小于1，意味着随着 $t$ 的增加，原始图像的信息（信号）在不断衰减。

- 方差 $\beta_t \mathbf{I}$：意味着在每一步都注入了新的噪声。

由于 $x_t$ 只依赖于 $x_{t-1}$，而与 $x_{t-2}$ 等更早的状态无关，因此这构成了一个马尔可夫链。随着 $t$ 趋向于 $T$（例如 $T=1000$），如果调度表设置得当，最终的分布 $x_T$ 将极其接近标准正态分布 $\mathcal{N}(0, \mathbf{I})$。此时，原始图像的所有信息都被抹去，只剩下纯粹的随机噪声 11。

##### 3.1.2 任意时刻的闭式采样 (The Nice Property)

如果我们要训练模型预测 $t=500$ 时刻的噪声，按照马尔可夫链的定义，似乎需要从 $x_0$ 采样出 $x_1$，再采样出 $x_2$，一直迭代500次。这在训练时极其低效。

幸运的是，利用高斯分布的再生性，我们可以推导出一个闭式解，允许我们直接从 $x_0$ 采样出 $x_t$。

为了简化符号，我们定义：

- $\alpha_t = 1 - \beta_t$

- $\bar{\alpha}_t = \prod_{s=1}^t \alpha_s$ （$\alpha$ 的累积乘积）

推导过程如下：

1. 由定义：$x_t = \sqrt{\alpha_t} x_{t-1} + \sqrt{1 - \alpha_t} \epsilon_{t-1}$

2. 展开 $x_{t-1}$：$x_{t-1} = \sqrt{\alpha_{t-1}} x_{t-2} + \sqrt{1 - \alpha_{t-1}} \epsilon_{t-2}$

3. 代入得：

    $$x_t = \sqrt{\alpha_t}(\sqrt{\alpha_{t-1}} x_{t-2} + \sqrt{1 - \alpha_{t-1}} \epsilon_{t-2}) + \sqrt{1 - \alpha_t} \epsilon_{t-1}$$

    $$x_t = \sqrt{\alpha_t \alpha_{t-1}} x_{t-2} + (\sqrt{\alpha_t(1 - \alpha_{t-1})} \epsilon_{t-2} + \sqrt{1 - \alpha_t} \epsilon_{t-1})$$

注意括号中的第二部分是两个独立高斯噪声的线性组合。根据高斯分布性质，$\mathcal{N}(0, \sigma_1^2) + \mathcal{N}(0, \sigma_2^2) \sim \mathcal{N}(0, \sigma_1^2 + \sigma_2^2)$。

这里合并后的方差为：$\alpha_t(1 - \alpha_{t-1}) + (1 - \alpha_t) = \alpha_t - \alpha_t \alpha_{t-1} + 1 - \alpha_t = 1 - \alpha_t \alpha_{t-1}$。

因此，两项噪声可以合并为一个新的噪声项 $\sqrt{1 - \alpha_t \alpha_{t-1}} \bar{\epsilon}$。

通过归纳法，我们可以一直递推回到 $x_0$，得到最终的**前向扩散公式**：

$$q(x_t | x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t) \mathbf{I})$$

或者写成重参数化形式：

$$x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon, \quad \epsilon \sim \mathcal{N}(0, \mathbf{I})$$

深入洞察：

这个公式是DDPM高效训练的基石。它告诉我们，$t$ 时刻的噪声图 $x_t$ 本质上就是原始图像 $x_0$ 和纯噪声 $\epsilon$ 的一个线性插值。$\sqrt{\bar{\alpha}_t}$ 是信号率（Signal Rate），$\sqrt{1 - \bar{\alpha}_t}$ 是噪声率（Noise Rate）。随着 $t$ 增加，$\bar{\alpha}_t$ 从接近1单调递减到接近0，意味着信号逐渐消失，噪声逐渐主导。这解释了为什么扩散模型被称为信噪比（SNR）不断降低的过程 11。

#### 3.2 反向过程：从混沌中重构秩序

反向过程（Reverse Process）的目标是求出后验分布 $q(x_{t-1} | x_t)$。如果我们知道了这个分布，就可以从纯噪声 $x_T$ 开始，采样出 $x_{T-1}$，再采样出 $x_{T-2}$，直到恢复出 $x_0$。

##### 3.2.1 真实的逆过程是不可解的

根据贝叶斯公式：

$$q(x_{t-1} | x_t) = \frac{q(x_t | x_{t-1}) q(x_{t-1})}{q(x_t)}$$

这里，$q(x_t | x_{t-1})$ 是已知的前向高斯核。然而，$q(x_{t-1})$ 涉及到对整个数据分布的积分，这是未知的且无法计算的。因此，我们无法直接得到真实的逆过程。

##### 3.2.2 神经网络的参数化近似

尽管真实的 $q(x_{t-1} | x_t)$ 未知，但Feller等人的理论研究表明，如果扩散过程的步长 $\beta_t$ 足够小，那么逆过程的分布形式也近似为高斯分布 18。基于此，我们可以使用一个神经网络（参数为 $\theta$）来预测这个高斯分布的参数：

$$p_\theta(x_{t-1} | x_t) = \mathcal{N}(x_{t-1}; \boldsymbol{\mu}_\theta(x_t, t), \boldsymbol{\Sigma}_\theta(x_t, t))$$

神经网络输入当前的噪声图 $x_t$ 和时间步 $t$，输出均值 $\boldsymbol{\mu}_\theta$ 和协方差 $\boldsymbol{\Sigma}_\theta$。

在DDPM的原始论文中，Ho等人做了一个重要的简化：他们将协方差 $\boldsymbol{\Sigma}_\theta$ 设为与前向过程相关的常数（例如 $\beta_t \mathbf{I}$ 或 $\tilde{\beta}_t \mathbf{I}$），而不让网络去学习它。这意味着神经网络只需要专注于学习均值 $\boldsymbol{\mu}_\theta(x_t, t)$。这一简化虽然在理论上可能损失了一些表达能力，但在实践中被证明能极大地稳定训练过程 11。

#### 3.3 训练目标：从复杂的ELBO到简单的MSE

如何训练这个网络？如前所述，我们需要优化变分下界（ELBO）。经过数学推导，ELBO可以被分解为三部分：

$$L_{\text{ELBO}} = \mathbb{E}_q$$

我们逐项分析：

1. $L_T$（先验匹配项）：由于前向过程是固定的，且 $x_T$ 接近标准高斯分布，这一项几乎是常数，在优化中可以忽略 15。

2. $L_0$（重建项）：这是最后一步从 $x_1$ 恢复 $x_0$ 的似然估计，类似于VAE的重建误差。

3. $L_{t-1}$（去噪匹配项）：这是核心部分。它要求网络预测的分布 $p_\theta(x_{t-1}|x_t)$ 尽可能接近真实的后验分布 $q(x_{t-1}|x_t, x_0)$。

关键在于 $q(x_{t-1}|x_t, x_0)$。注意，虽然 $q(x_{t-1}|x_t)$ 是未知的，但如果我们**已知 $x_0$**，那么 $q(x_{t-1}|x_t, x_0)$ 是完全可解的！通过贝叶斯公式和高斯性质，可以推导出它也是一个高斯分布，其均值 $\tilde{\boldsymbol{\mu}}_t(x_t, x_0)$ 是 $x_t$ 和 $x_0$ 的线性组合：

$$\tilde{\boldsymbol{\mu}}_t(x_t, x_0) = \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1 - \bar{\alpha}_t} x_0 + \frac{\sqrt{\alpha_t}(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t} x_t$$

既然我们知道真实的目标均值 $\tilde{\boldsymbol{\mu}}_t$，网络的任务就是预测出这个均值。

再进一步，利用前向公式 $x_0 = \frac{x_t - \sqrt{1 - \bar{\alpha}_t}\epsilon}{\sqrt{\bar{\alpha}_t}}$ 将 $x_0$ 替换掉，我们会发现 $\tilde{\boldsymbol{\mu}}_t$ 最终只与 $x_t$ 和噪声 $\epsilon$ 有关。

经过繁琐的代数化简（在此省略中间步骤），Ho等人发现：预测均值 $\boldsymbol{\mu}_\theta$ 等价于预测噪声 $\epsilon$。

于是，损失函数被简化为预测噪声 $\epsilon_\theta(x_t, t)$ 与真实噪声 $\epsilon$ 之间的均方误差（MSE）：

$$L_{\text{simple}}(\theta) = \mathbb{E}_{x_0, \epsilon, t} \left[ \left\| \epsilon - \epsilon_\theta(\sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon, t) \right\|^2 \right]$$

从底层理解这一飞跃：

这个简化的Loss函数不仅仅是数学上的巧合，它具有深刻的物理意义。所有的复杂推导最终归结为一个直观的目标：网络只需要看着那张噪点图，然后猜出刚才到底加了什么噪声进去。如果网络能准确猜出噪声，它就能通过减去这个噪声来还原图像。这一发现将生成式建模问题转化为了一个类似于去噪自编码器（Denoising Autoencoder）的监督学习问题，极大地降低了实现的门槛 15。

#### 3.4 DDPM 采样算法与缺陷

训练好的模型本质上是一个噪声预测器。采样过程（Inference）如下：

1. 从标准正态分布采样 $x_T \sim \mathcal{N}(0, \mathbf{I})$。

2. 从 $t=T$ 倒数至 $1$：

    - 预测噪声：$z = \epsilon_\theta(x_t, t)$

    - 计算去噪后的均值。

    - **关键一步**：为了符合概率分布的定义，DDPM在每一步去噪后，会人为地加回一点点随机噪声 $\sigma_t z$（除了最后一步）。

    - 更新公式：$x_{t-1} = \frac{1}{\sqrt{\alpha_t}} (x_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon_\theta(x_t, t)) + \sigma_t z$

3. 最终得到 $x_0$。

DDPM的缺陷：

DDPM的采样过程严格遵循马尔可夫链。为了保证每一步的高斯近似成立，步长 $\beta_t$ 必须非常小，这就导致总步数 $T$ 必须非常大（通常为1000）。这意味着生成一张图像需要运行庞大的U-Net网络1000次。这导致了极高的延迟，无法满足实时应用需求。例如，在高端GPU上生成一张图可能需要几秒甚至几十秒，而GAN只需要几毫秒 7。

---

### 第四章 DDIM：打破马尔可夫链的束缚

面对DDPM的效率瓶颈，Jiaming Song等人在2020年底提出了去噪扩散隐式模型（Denoising Diffusion Implicit Models, DDIM）。DDIM的核心贡献在于证明了：**只要保持边缘分布 $q(x_t|x_0)$ 不变，前向过程的联合分布形式可以是任意的。**

#### 4.1 非马尔可夫前向过程 (Non-Markovian Forward Process)

DDPM的推导依赖于 $q(x_t|x_{t-1})$ 这一马尔可夫假设。然而，训练目标 $L_{\text{simple}}$ 实际上只依赖于边缘分布 $q(x_t|x_0)$（即我们如何从 $x_0$ 构造 $x_t$ 来训练网络）。

DDIM提出了一类新的非马尔可夫前向过程，其特点是：

1. 它依然保证 $q(x_t|x_0) = \mathcal{N}(\sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t) \mathbf{I})$，这确保了我们可以**直接复用已经训练好的DDPM模型权重**，而不需要重新训练。

2. 它不再强求 $x_t$ 仅依赖于 $x_{t-1}$，而是允许 $x_t$ 依赖于 $x_{t-1}$ 和 $x_0$ 的组合。

#### 4.2 广义的逆过程采样公式

在这一新的框架下，Song等人推导出了一个更通用的逆过程更新公式。给定当前的噪点图 $x_t$ 和模型预测的噪声 $\epsilon_\theta(x_t)$，我们可以首先估计出一个预测的 $x_0$（记为 $\hat{x}_0$）：

$$\hat{x}_0 = \frac{x_t - \sqrt{1 - \bar{\alpha}_t}\epsilon_\theta(x_t)}{\sqrt{\bar{\alpha}_t}}$$

这一步在直觉上相当于模型试图穿透当前的迷雾，直接看清原始图像的模样。虽然在早期（$t$ 较大时）这个预测很不准确，但这代表了当前最合理的去噪方向。

基于 $\hat{x}_0$ 和 $\epsilon_\theta(x_t)$，DDIM导出了 $x_{t-1}$ 的生成公式：

$$x_{t-1} = \underbrace{\sqrt{\bar{\alpha}_{t-1}} \hat{x}_0}_{\text{确定性恢复项}} + \underbrace{\sqrt{1 - \bar{\alpha}_{t-1} - \sigma_t^2} \cdot \epsilon_\theta(x_t)}_{\text{指向当前噪声的方向}} + \underbrace{\sigma_t \epsilon}_{\text{随机噪声项}}$$

其中，$\sigma_t$ 是一个控制随机性的超参数，定义为：

$$\sigma_t = \eta \sqrt{\frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t}} \sqrt{1 - \frac{\bar{\alpha}_t}{\bar{\alpha}_{t-1}}}$$

#### 4.3 $\eta$ 参数：从随机到确定

公式中的 $\eta$（eta）是一个介于0和1之间的参数，它像一个滑块一样控制着采样过程的性质，连接了DDPM和DDIM 21。

##### 4.3.1 当 $\eta = 1$ 时：回归 DDPM

如果令 $\eta = 1$，代入计算你会发现，$\sigma_t$ 的值恰好等于DDPM中的方差项。此时，公式中的随机噪声项 $\sigma_t \epsilon$ 占据主导地位，整个过程退化为标准的DDPM采样。这意味着DDPM只是DDIM这一广义框架下的一个特例。

##### 4.3.2 当 $\eta = 0$ 时：成就 DDIM

最令人兴奋的情况发生在 $\eta = 0$ 时。此时 $\sigma_t = 0$，公式中的随机噪声项完全消失！

$$x_{t-1} = \sqrt{\bar{\alpha}_{t-1}} \hat{x}_0 + \sqrt{1 - \bar{\alpha}_{t-1}} \cdot \epsilon_\theta(x_t)$$

这意味着，一旦初始的随机噪声 $x_T$ 给定，整个生成轨迹 $x_T \to x_{T-1} \to \dots \to x_0$ 就是完全确定的（Deterministic）。没有任何随机扰动。

这就是**隐式（Implicit）**模型的含义：它通过确定性的映射定义了潜在变量到数据的分布，类似于GAN或Flow模型，而不是像DDPM那样的概率性马尔可夫链。

#### 4.4 DDIM 的核心优势

##### 4.4.1 采样加速 (Thinking in Steps)

由于DDIM打破了马尔可夫限制，反向过程不再需要严格逼近高斯分布的微小变化。这使得我们可以进行跳步采样。

在DDPM中，我们必须走 $1000 \to 999 \to 998 \dots$。

在DDIM中，我们可以定义一个子序列 $\tau = [1000, 950, 900, \dots, 0]$，只走20步。

实验证明，由于DDIM的确定性更新更加稳定，即使在大步长下，它依然能保持极高的图像质量。通常，DDIM在50步采样下的FID分数（衡量图像质量的指标）就能媲美DDPM在1000步下的表现，实现了10倍到20倍的加速 7。

##### 4.4.2 一致性与语义插值

DDIM的确定性性质带来了两个独特的优势：

1. 一致性（Consistency）：在DDPM中，即使固定了初始噪声 $x_T$，由于每一步都注入新噪声，生成的 $x_0$ 也会千差万别。而在DDIM中，同一个 $x_T$ 永远生成同一张图。这对于应用开发至关重要（例如用户希望微调Prompt但保持构图不变）。

2. 潜在空间插值：我们可以在两个初始噪声 $x_T^{(1)}$ 和 $x_T^{(2)}$ 之间进行球面线性插值（Slerp），然后用DDIM采样。结果会显示出两张图像之间平滑的语义过渡（例如从一只狗平滑变形成一只猫），这是DDPM难以做到的 8。

##### 4.4.3 图像反转 (Inversion)

由于DDIM的更新公式近似于常微分方程（ODE）的欧拉积分，这个过程在数学上是可逆的。我们可以把一张真实照片 $x_0$ 输入，反向运行DDIM公式（加噪方向），得到其对应的精确噪声表示 $x_T$。这被称为DDIM Inversion，是许多图像编辑技术（如Pix2Pix-Zero）的基础 25。

以下表格总结了DDPM与DDIM的关键对比：

| 特性维度 | DDPM (η=1) | DDIM (η=0) |
| --- | --- | --- |
| 反向过程性质 | 随机 | 确定性 |
| 理论基础 | 马尔可夫链、变分推断 | 非马尔可夫过程、得分匹配/ODE |
| 采样步数 | 必须大 (如 1000) | 可变，小步数 (如 20-50) 效果好 |
| 推理速度 | 极慢 (数秒/图) | 快 (亚秒级/图) |
| 生成质量 (FID) | 高步数下极优 | 低步数下优于DDPM，高步数略逊 |
| 一致性 | 差 (结果随过程随机变化) | 优 (结果仅取决于初始噪声) |
| 实现难度 | 需从头训练 | **可直接复用DDPM权重** |

---

### 第五章 现代应用：Stable Diffusion 与生态系统

理解了DDPM和DDIM的底层原理后，我们就能看懂当今最火爆的生成模型——Stable Diffusion（稳定扩散）是如何工作的。Stable Diffusion 并非一个新的算法，而是将上述扩散模型理论应用在了一个特殊的空间——潜在空间（Latent Space）中 26。

#### 5.1 潜在扩散模型 (Latent Diffusion Models, LDM)

DDPM和DDIM最初都是直接在像素空间（Pixel Space）操作。对于一张 $512 \times 512$ 的彩色图片，输入维度高达 $512 \times 512 \times 3 \approx 78$万。在如此高维的空间进行扩散和去噪，计算成本极其昂贵，且模型需要浪费大量算力去学习人眼并不敏感的高频细节（如微小的噪点纹理）。

Stable Diffusion 引入了感知压缩（Perceptual Compression）的理念，分为两个阶段：

1. 图像压缩（VAE）：首先训练一个变分自编码器（VAE）。它的编码器将 $512 \times 512 \times 3$ 的图像压缩成 $64 \times 64 \times 4$ 的潜在向量（Latent Vector）。这个压缩过程的压缩比是 $8 \times 8 = 64$ 倍。在这个低维的潜在空间中，保留了图像的语义信息（轮廓、物体、颜色），而丢弃了冗余的像素细节。

2. 潜在空间扩散：然后，我们在 $64 \times 64 \times 4$ 的潜在空间中训练一个扩散模型（通常是U-Net结构）。这个U-Net不再预测像素的噪声，而是预测潜在特征的噪声。

由于计算量大幅减少，Stable Diffusion 可以在消费级显卡（如NVIDIA RTX 3060）上运行，而不需要TPU集群。DDIM在这里通常被用作默认的采样器，以确保在50步内生成高质量图像 28。

#### 5.2 无分类器引导 (Classifier-Free Guidance)

在Stable Diffusion的WebUI中，我们经常会调节一个参数 CFG Scale（通常设为7-12）。这背后的技术叫无分类器引导（Classifier-Free Guidance, CFG）。

DDPM/DDIM 本身生成的是无条件分布 $p(x)$。为了实现文生图，我们需要条件分布 $p(x|text)$。

早期的做法是训练一个额外的分类器来指导生成，但这很麻烦。

CFG提出了一种巧妙的方法：在训练U-Net时，有一定概率（如10%）将文本条件置空（Null），让模型同时学习有条件生成 $\epsilon_\theta(x_t, \text{text})$ 和无条件生成 $\epsilon_\theta(x_t, \emptyset)$。

在采样（DDIM）时，我们计算两者的差值，并放大这个差异：

$$\tilde{\epsilon} = \epsilon_\theta(x_t, \emptyset) + w \cdot (\epsilon_\theta(x_t, \text{text}) - \epsilon_\theta(x_t, \emptyset))$$

其中 $w$ 就是 CFG Scale。

- 这个公式的几何含义是：在噪声空间中，让生成方向远离无条件结果，强力推向有条件结果。

- $w$ 越大，图像越符合提示词（Prompt），但多样性降低，且过大会导致图像过饱和或崩坏 20。

#### 5.3 采样器的百花齐放

除了DDIM，现在Stable Diffusion中还有Euler a, DPM++ 2M Karras等采样器。

- Euler / Heun：这些是基于常微分方程（ODE）数值解法的采样器。因为DDIM ($\eta=0$) 本质上就是一个ODE，所以可以直接套用数学上成熟的ODE求解器。

- DPM++：这是一类专门为扩散模型优化的求解器，能在极少的步数（如10-20步）下达到极高的收敛精度。

- Ancestral (如 Euler a, DPM++ SDE)：这些采样器会在每一步注入随机噪声（类似DDPM），生成的图像不收敛，每一帧都在微小变化，能带来更多样的细节，但也更难控制 30。

尽管采样器层出不穷，但它们的核心逻辑依然建立在DDPM定义的噪声预测网络和DDIM定义的非马尔可夫加速思想之上。

---

### 第六章 结论与展望

本报告从概率分布的底层知识出发，详细梳理了扩散模型的发展脉络。

我们看到，DDPM通过巧妙的马尔可夫链设计和变分推断的简化，将复杂的生成问题转化为简单的噪声预测（MSE）问题，解决了GAN训练不稳定的难题。

随后，DDIM通过洞察扩散过程的非马尔可夫性质，引入确定性采样，成功解决了DDPM推理速度慢的致命弱点，并为后续的潜在空间操作打开了大门。

对于初学者而言，理解以下三个核心点至关重要：

1. **高斯分布与重参数化**是扩散模型能进行数学推导的基石。

2. **预测噪声**是训练神经网络的唯一目标，它等价于学习数据的梯度（Score Matching）。

3. **确定性采样（DDIM）**是实现速度与质量平衡的关键，也是现代生成式AI应用（如Stable Diffusion）的默认引擎。

随着技术的演进，未来我们可能会看到一步生成的扩散模型（Consistency Models）或结合Transformer架构的新模型（DiT, Sora），但无论形式如何变化，DDPM和DDIM所建立的去噪生成范式，已然成为了人工智能历史上的一座丰碑。

---

**<font color="#2ecc71">✅ 已格式化</font>**
